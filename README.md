# HACK: Automating the generating of HArdware Component Knowledge Bases

## Dependencies

We use a few applications that you'll need to install and be sure are on your
PATH.

For OS X using [homebrew](https://brew.sh):

```bash
$ brew install poppler
$ brew install postgresql
$ brew install libpng freetype pkg-config
```

On Debian-based distros:

```bash
$ sudo apt install libxml2-dev libxslt-dev python3-dev
$ sudo apt build-dep python-matplotlib
$ sudo apt install poppler-utils
$ sudo apt install postgresql
```

For the Python dependencies, we recommend using a
[virtualenv](https://virtualenv.pypa.io/en/stable/). Once you have cloned the
repository, change directories to the root of the repository and run

```bash
$ virtualenv -p python3 .venv
```

Once the virtual environment is created, activate it by running

```bash
$ source .venv/bin/activate
```

Any Python libraries installed will now be contained within this virtual
environment. To deactivate the environment, simply run `deactivate`.

Then, install Fonduer and any other Python dependencies by running:

```bash
$ make dev
```

## Downloading the Datasets

Each component has its own dataset which must be downloaded before running. To
do so, navigate to each component's directory and run the download data script.
Note that you must navigate to the directory before running the script, since
the script will automatically unpack into the `data` directory.

For example, to download the Op-Amp dataset:

```
$ cd hack/opamps/
$ ./download_data.sh
```

## Running

After installing all the requirements, and ensuring the necessary databases
are created, you can run each individual hardware component script.

To run all relations at once on a subset of 500 datasheets (as running all
relations for all datasheets takes about 10+ hrs), you can run the following
(assuming you have a four-core machine):

### Transistors

```bash
$ createdb transistors
$ transistors --stg-temp-min --stg-temp-max --polarity --ce-v-max --parse
--first-time --max-docs 500 --parallel 4 --conn-string postgresql:///transistors
```

### Op Amps

```bash
$ createdb opamps
$ opamps --gain --current --parse --first-time --max-docs 500 --parallel 4
--conn-string postgresql:///opamps
```

### Circular Connectors

```bash
$ createdb circular_connectors
$ python hack/circular_connectors/circular_connectors.py
```

For more detailed options, run `transistors -h` or `opamps -h` to see a list of
all possible options.

## Analysis
For our analysis, we use candidates generated by `fonduer` to create a set of
entities which are scored against ground-truth gold labels to compare knowledge
base accuracy. These candidates are taken only from datasheets that both we and
Digikey have labels for.

Running `analysis.py` will score both the `test` and `dev` dataset splits and
thus will output three scores: one for `test`, one for `dev`, and one for the
`analysis` split of documents (datasheets from `dev` and `test` that also occur
in Digikey's data).

### Transistors
For our transistor analysis, we compare our automatically generated output with
Digikey using `ce_v_max` (collector emitter voltage max).

#### Generate Entity CSVs
After running `transistors` to generate a HACK knowledge base and a set of
entity probability CSVs, you can then run the analysis scripts to score those
entities against our ground truth gold labels and output a file of discrepancies
for further categorization:

```bash
$ python hack/transistors/analysis.py
```

Scoring will produce a set of false positive and false negative entities which
are then written to `analysis_discrepancies.csv` for manual evaluation.

#### Use Existing Entities
For analysis purposes, you can use the included entity CSVs that were generated
from our knowledge bases. In order to exactly replicate our results, you can use
the already created entity CSVs found in `hack/transistors/analysis/` by
running:

```bash
$ python hack/transistors/analysis.py
```

This will also ouput an F1 Score and a `data_discrepancies.csv` file for manual
debugging.

### Scoring Digi-Key
To compare scores with Digikey, we grade Digikey's existing data with the same
ground truth labels and on the same datasheets used to score our automated
output:

```bash
$ python hack/transistors/data/utils/compare_gold.py
```

This will output an F1 Score for Digikey and a `digikey_discrepancies.csv' file
for manual evaluation.

### Op Amps
For our opamp analysis, we evalutate our output against Digikey's knowledge base
using both relations: `typ_gbp` (typical gain bandwidth product) and
`typ_supply_current` (typical supply or quiescent current).

Running `analysis.py` will generate two sets of scores: one for `typ_gbp` and
one for `typ_supply_current`.

#### Generate Entity CSVs
After running `opamps` to generate a HACK knowledge base and a set of
entity probability CSVs, you can then run the analysis scripts to score those
entities against our ground truth gold labels and output a file of discrepancies
for further categorization:

```bash
$ python hack/opamps/analysis.py
```

Scoring will produce a set of false positive and false negative entities which
are then written to `analysis_discrepancies.csv` for manual evaluation.

#### Use Existing Entities
For analysis purposes, you can use the included entity CSVs that were generated
from our knowledge bases. In order to exactly replicate our results, you can use
the already created entity CSVs found in `hack/opamps/analysis/` by
running:

```bash
$ python hack/opamps/analysis.py
```

This will also ouput an F1 Score and a `data_discrepancies.csv` file for manual
debugging.

### Scoring Digi-Key
To compare scores with Digikey, we grade Digikey's existing data with the same
ground truth labels and on the same datasheets used to score our automated
output:

```bash
$ python hack/opamps/data/utils/compare_gold.py
```

This will output an F1 Score for Digikey and a `digikey_discrepancies.csv' file
for manual evaluation.
